{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "we should not trust this dataset completely - labels are not certain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.chdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/github/RiboVsPolyA/examples'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "#Author: Ioannis Anastopoulos\n",
    "from sklearn.metrics import r2_score,confusion_matrix, accuracy_score,roc_curve,auc,precision_recall_fscore_support,f1_score, average_precision_score\n",
    "from scipy.stats import pearsonr\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(y_pred - y_true)))\n",
    "\n",
    "def F_score(Y_true,predict_classes ,classes=None, plot=False,average=None):\n",
    "    if classes is None:\n",
    "        classes=range(len(set(Y_true)))\n",
    "    eval_metrics_matrix=precision_recall_fscore_support(Y_true,predict_classes,labels=classes,average=average)\n",
    "    f_score_df=pd.DataFrame(eval_metrics_matrix[2], columns=['F_score'],index=classes)\n",
    "    f_score_df=f_score_df.drop_duplicates()\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10,10))\n",
    "        ax=f_score_df.plot(kind='bar', figsize=(7,10))\n",
    "        for p in ax.patches:\n",
    "            ax.annotate(str(round(p.get_height(),2)), (p.get_x() * 1.005, p.get_height() * 1.005))\n",
    "        plt.title('F1_score')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    return f_score_df\n",
    "\n",
    "def confusion(Y_true,predict_classes,classes=None,plot=False, title='Confusion Matrix',fontsize=16,cmap='tab20',normalize=False):\n",
    "\n",
    "    if classes is None:\n",
    "        classes=range(len(set(predict_classes)))\n",
    "\n",
    "    conf_matrix=confusion_matrix(Y_true, predict_classes, labels=classes)\n",
    "\n",
    "    if normalize:\n",
    "        total=conf_matrix.sum(axis=0) #summing actual predictions\n",
    "        conf_matrix= conf_matrix/total\n",
    "\n",
    "    df_cm = pd.DataFrame(conf_matrix, index=classes,\n",
    "                  columns=classes)\n",
    "    #sns.set(font_scale=5)#for label size\n",
    "    if plot:\n",
    "        plt.figure(figsize=(10,10))\n",
    "        sns.heatmap(df_cm, annot=True,annot_kws={\"size\":fontsize*(1/2) },cmap=cmap)# font size\n",
    "        #fig=conf_hm.get_figure()\n",
    "        plt.yticks(fontsize=fontsize+4)\n",
    "        plt.xticks(fontsize=fontsize+4)\n",
    "        plt.title(title, fontsize=fontsize+10)\n",
    "        #fig.savefig(out,dpi=300)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    return conf_matrix\n",
    "\n",
    "def to_categorical(y, num_classes):\n",
    "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
    "    return np.eye(num_classes, dtype='uint8')[y]\n",
    "\n",
    "def ROC(y_true, y_pred,classes=None,title=None,plot=False):\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    lw=4\n",
    "\n",
    "    if isinstance(y_true, pd.DataFrame):\n",
    "        y_true=y_true.values\n",
    "    if isinstance(y_pred, pd.DataFrame):\n",
    "        y_pred=y_pred.values\n",
    "\n",
    "\n",
    "    if classes is None:\n",
    "        classes=set(list(y_true.flatten())) #removing dups, and i think itll only work for binary cases\n",
    "\n",
    "    if len(classes)>2:\n",
    "        #y_true = to_categorical(y_true, len(classes))\n",
    "        #y_pred = to_categorical(y_pred, len(classes))\n",
    "        \n",
    "        fpr = dict()\n",
    "        tpr = dict()\n",
    "        roc_auc = dict()\n",
    "\n",
    "        for i,cl in enumerate(classes):\n",
    "            fpr[cl], tpr[cl], _ = roc_curve(y_true[:,i], y_pred[:, i])\n",
    "            roc_auc[cl] = auc(fpr[cl], tpr[cl])\n",
    "        \n",
    "        if plot: \n",
    "            colors = plt.cm.get_cmap('tab20',len(classes)) #best line of code IN THE UNIVERSE\n",
    "\n",
    "            for i, color in zip(range(len(classes)), colors.colors):\n",
    "                cl = classes[i]\n",
    "                plt.plot(fpr[cl], tpr[cl], color=colors.colors[i], lw=lw,\n",
    "                     label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                     ''.format(cl, roc_auc[cl]))\n",
    "            plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "            plt.xlim([-0.03, 1.05])\n",
    "            plt.ylim([-0.03, 1.05])\n",
    "            plt.xlabel('False Positive Rate', fontsize=10)\n",
    "            plt.ylabel('True Positive Rate',fontsize=10)\n",
    "            plt.title(title, fontsize=12)\n",
    "            plt.xticks(fontsize=10)\n",
    "            plt.yticks(fontsize=10)\n",
    "            plt.legend(loc=\"lower right\",prop={'size': 15})\n",
    "            #plt.savefig('/projects/sysbio/users/ianastop/cm_region_results/plots/%s_ROC.png'%self.out,dpi=300)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "        return (fpr, tpr, roc_auc)\n",
    "\n",
    "    else:\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        if plot:\n",
    "            plt.plot(fpr, tpr, color='darkorange', lw=4, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "            plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "            plt.xlim([-0.03, 1.05])\n",
    "            plt.ylim([-0.03, 1.05])\n",
    "            plt.xlabel('False Positive Rate', fontsize=10)\n",
    "            plt.ylabel('True Positive Rate',fontsize=10)\n",
    "            plt.title(title, fontsize=12)\n",
    "            plt.xticks(fontsize=10)\n",
    "            plt.yticks(fontsize=10)\n",
    "            plt.legend(loc=\"lower right\",prop={'size': 10})\n",
    "            #plt.savefig('/projects/sysbio/users/ianastop/cm_region_results/plots/%s_ROC.png'%self.out,dpi=300)\n",
    "            return( fpr, tpr, roc_auc)\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        print(fpr, tpr)\n",
    "        return fpr,tpr,roc_auc\n",
    "\n",
    "\n",
    "def regression_eval(y_true,y_pred, axis=None):\n",
    "    '''\n",
    "    Function computes pearson, r2 and rmse row wise or column wise\n",
    "    Returns a list for each metric for each row or column\n",
    "\n",
    "    axis =0/1 if the vector predicted has multiple rows and columns: for expression matrices\n",
    "    if the vectors has multiple samples predicted for 1 variable : for drug response vector of each drug individually\n",
    "    '''\n",
    "    #calculating metrics on a per sample basis\n",
    "    if axis ==0:\n",
    "        r_list = []\n",
    "        r2_list = []\n",
    "        rmse_list = []\n",
    "        for i, vec in enumerate(y_true):\n",
    "            r_list +=[pearsonr(vec, y_pred[i])[0]]\n",
    "            r2_list += [r2_score(vec, y_pred[i])]\n",
    "            rmse_list += [rmse(vec,y_pred[i])]\n",
    "        r = np.mean(r_list)\n",
    "        r2 = np.mean(r2_list)\n",
    "        rmse_score = np.mean(rmse_list)\n",
    "    elif axis == 1:\n",
    "        r_list = []\n",
    "        r2_list = []\n",
    "        rmse_list = []\n",
    "        for i, vec in enumerate(y_true.T):\n",
    "            r_list +=[pearsonr(vec, y_pred.T[i])[0]]\n",
    "            r2_list += [r2_score(vec, y_pred.T[i])]\n",
    "            rmse_list += [rmse(vec,y_pred.T[i])]\n",
    "        r = np.mean(r_list)\n",
    "        r2 = np.mean(r2_list)\n",
    "        rmse_score = np.mean(rmse_list)\n",
    "    elif axis is None:\n",
    "        r, _ = pearsonr(y_true.flatten(), y_pred.flatten())\n",
    "        r2 = r2_score(y_true.flatten(), y_pred.flatten())\n",
    "        rmse_score = rmse(y_true.flatten(), y_pred.flatten())\n",
    "    return r,r2,rmse_score\n",
    "\n",
    "def classification_eval(y_true,y_pred, y_proba,classes=None):\n",
    "    if len(y_proba.shape)>=2:\n",
    "        y_pred = np.argmax(y_proba, axis=1)\n",
    "    acc = accuracy_score(y_true,y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    roc_auc = ROC(y_true, y_proba,classes=classes)[-1]\n",
    "    precision = average_precision_score(y_true, y_proba, average='weighted')\n",
    "    \n",
    "    return acc, f1, roc_auc, precision\n",
    "        \n",
    "def node_classification_eval():\n",
    "    pass \n",
    "\n",
    "def corr_plot(y_true, y_pred, title='Fig Title', ylabel='Y label', xlabel='X label', out_fn='out.png', log_values=False):\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=3,figsize=(10,10))\n",
    "    i=0\n",
    "    j=0\n",
    "    np.random.seed(42)\n",
    "    for idx,sample_idx in enumerate(np.random.choice(np.arange(y_true.shape[0]),9)):\n",
    "\n",
    "        ax_row =axes[i] #select row  to plot in\n",
    "        ax = ax_row[j]\n",
    "        if log_values:\n",
    "            observed = [np.log(x+1) for x in y_true[int(sample_idx/2)]]\n",
    "            predicted = [np.log(x+1) for x in y_pred[int(sample_idx/2)]]\n",
    "        else:\n",
    "            observed = y_true[int(sample_idx/2)]\n",
    "            predicted = y_pred[int(sample_idx/2)]\n",
    "            \n",
    "        ax.scatter(observed, predicted, s=1, alpha=0.6, marker='o')\n",
    "\n",
    "        ax.set_title(\"Random sample %d\"%(idx+1))\n",
    "\n",
    "        if j==2:\n",
    "            i+=1\n",
    "            j=0\n",
    "        else:\n",
    "            j+=1\n",
    "        r = pearsonr(y_true[int(sample_idx/2)], y_pred[int(sample_idx/2)])[0]\n",
    "        r2 = r2_score(y_true[int(sample_idx/2)], y_pred[int(sample_idx/2)])\n",
    "        ax.text(min(observed), 0.95*max(predicted), 'pearson coeff: %.3f'%r)\n",
    "        ax.text(min(observed), 0.8*max(predicted), r'$R^2$: %.3f'%r2)\n",
    "\n",
    "    #     handles, labels = ax.get_legend_handles_labels()\n",
    "    #     by_label = dict(zip(labels, handles))\n",
    "    #     ax.legend(by_label.values(), by_label.keys())\n",
    "        ax.set_ylabel(ylabel, fontsize=10)\n",
    "        ax.set_xlabel(xlabel, fontsize=10)\n",
    "\n",
    "    st = fig.suptitle(title, fontsize=15)\n",
    "    st.set_y(1.05)\n",
    "    fig.subplots_adjust(top=0.85)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_fn, dpi=300)\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Treehouse Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../results/SRP026013_TPM_log2_plus_1.TH.balanced_maxdepth1_results.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-dbe56f75bdd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msrp_tpm_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../results/SRP026013_TPM_log2_plus_1.TH.balanced_maxdepth1_results.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../results/SRP026013_TPM_log2_plus_1.TH.balanced_maxdepth1_results.tsv'"
     ]
    }
   ],
   "source": [
    "srp_tpm_df = pd.read_csv(\"../results/SRP026013_TPM_log2_plus_1.TH.balanced_maxdepth1_results.tsv\", index_col=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srp_tpm_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = np.array([0]*srp_tpm_df.shape[0])\n",
    "pred_labels = srp_tpm_df.Ribo.values\n",
    "pred_proba = srp_tpm_df.Proba_1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srp_tpm_df.iloc[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, f1, roc_auc, precision= classification_eval(true_labels,pred_labels,pred_proba, classes=[0,1])\n",
    "print('Accuracy: {}\\nF1-score: {}'.format(acc, f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using refine.bio Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "srp_tpm_df = pd.read_csv(\"../results/SRP026013_TPM_log2_plus_1.balanced_maxdepth1_results.tsv\", index_col=0, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "srp_tpm_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = np.array([0]*srp_tpm_df.shape[0])\n",
    "pred_labels = srp_tpm_df.Ribo.values\n",
    "pred_proba = srp_tpm_df.Proba_1.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.     0.0625 0.8125 0.9375 1.    ] [nan nan nan nan nan]\n",
      "Accuracy: 0.0625\n",
      "F1-score: 0.11764705882352941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc, f1, roc_auc, precision= classification_eval(true_labels,pred_labels,pred_proba, classes=[0,1])\n",
    "print('Accuracy: {}\\nF1-score: {}'.format(acc, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
