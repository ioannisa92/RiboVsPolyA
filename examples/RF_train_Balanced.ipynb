{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disease balanced input data to RF (run2): analysis of classifier resutls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, precision_recall_curve,average_precision_score,confusion_matrix,roc_auc_score,roc_curve\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "os.chdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = np.load('../results/rf_gscv_best_params.npy').item()\n",
    "depth = best_params['max_depth']\n",
    "n_estimators = best_params['n_estimators']\n",
    "min_samples_leaf = best_params['min_samples_leaf']\n",
    "min_samples_split = best_params['min_samples_split']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data_test/TreehousePEDv9_Ribodeplete_clinical_metadata.2019-03-25.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-71722fc08af2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mribo_clinical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data_test/TreehousePEDv9_Ribodeplete_clinical_metadata.2019-03-25.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'disease'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpoly_clinical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data_test/clinical_TumorCompendium_v10_PolyA_2019-07-25.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'disease'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mall_clinical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mribo_clinical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoly_clinical\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1166\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1168\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1169\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1998\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data_test/TreehousePEDv9_Ribodeplete_clinical_metadata.2019-03-25.tsv'"
     ]
    }
   ],
   "source": [
    "ribo_clinical = pd.read_csv(\"../data_test/TreehousePEDv9_Ribodeplete_clinical_metadata.2019-03-25.tsv\", index_col=0, sep='\\t')['disease']\n",
    "poly_clinical = pd.read_csv(\"../data_test/clinical_TumorCompendium_v10_PolyA_2019-07-25.tsv\", index_col=0, sep='\\t')['disease']\n",
    "all_clinical = pd.concat([ribo_clinical, poly_clinical], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fpr_tpr(mat):\n",
    "    '''\n",
    "    Function takes in a confusion matrix\n",
    "    Retunr false positive rate (FPR) and true positive (TPR)\n",
    "    \n",
    "    Only works for binary cases\n",
    "    '''\n",
    "    tn, fp, fn, tp = mat.ravel()\n",
    "    if len(mat.shape) !=2:\n",
    "        raise ValueError('Function can only handle binary classification cases')\n",
    "    tot = mat.sum(axis=1) # total negative(0) and positive(1) labels\n",
    "    FPR = fp/tot[0]\n",
    "    TPR = tp/tot[1]\n",
    "        \n",
    "    return FPR,TPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data: disease balanced data\n",
    "X = pd.read_csv('../data_test/MergedData_Balanced.tsv', sep='\\t', index_col=0)\n",
    "Y = pd.read_csv('../data_test/MergedLabels_Balanced.tsv', sep='\\t', index_col=0)\n",
    "\n",
    "# splitting data into train and test\n",
    "# data is split based on disease\n",
    "# This means that disease prevalence is maintained in both train and test subsets\n",
    "# This ensures reproducibility of the method\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, stratify=Y, random_state=42, test_size=0.3)\n",
    "\n",
    "#loading random forest model with balanced params\n",
    "model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
    "                       criterion='gini', max_depth=depth, max_features='auto',\n",
    "                       max_leaf_nodes=None, max_samples=None,\n",
    "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "                       min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split,\n",
    "                       min_weight_fraction_leaf=0.0, n_estimators=n_estimators,\n",
    "                       n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
    "                       warm_start=False)\n",
    "\n",
    "\n",
    "#fitting model to data\n",
    "model.fit(X_train, Y_train.values.ravel())\n",
    "pred = model.predict(X_test)\n",
    "#scoring for accuracy\n",
    "score = (model.score(X_test, Y_test.values.ravel()))\n",
    "\n",
    "#getting probability scores for each sample\n",
    "# probability scores for both classes (RiboD, PolyA) will sum to 1\n",
    "y_proba = model.predict_proba(X_test)[:,1]\n",
    "precision, recall, _ = precision_recall_curve(Y_test, y_proba)\n",
    "\n",
    "# mean precision score\n",
    "mean_precision = average_precision_score(Y_test, y_proba)\n",
    "pred_proba = model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "res = {} # results dictionary to be used later for downstream analysis\n",
    "\n",
    "res['test_labels'] = Y_test.values.ravel()\n",
    "res['pred_labels'] = pred\n",
    "res['pred_proba'] = pred_proba\n",
    "res['acc'] = score\n",
    "#res['oob_score'] = model.oob_score_\n",
    "res['model'] = model\n",
    "res['average_precision'] = mean_precision\n",
    "res['precision'] = precision\n",
    "res['recall'] = recall\n",
    "res['genes'] = X.columns.tolist()\n",
    "res['importances'] = model.feature_importances_\n",
    "res['test_samples'] = X_test.index.values\n",
    "\n",
    "#saving results\n",
    "np.save('../results/RF_results_balanced.npy', res)\n",
    "pickle.dump(model, open('../models/RiboVsPoly_balanced.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.hstack([pred.reshape(-1,1),pred_proba, Y_test.values]), columns=[\"Ribo\", \"Proba_Poly\", \"Proba_Ribo\", \"TrueLabel\"], index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "# keep probabilities for the positive outcome only\n",
    "rf_probs = df.Proba_Ribo.values\n",
    "# calculate scores\n",
    "rf_auc = roc_auc_score(Y_test, rf_probs)\n",
    "# summarize scores\n",
    "print('Logistic: ROC AUC=%.3f' % (rf_auc))\n",
    "# calculate roc curves\n",
    "rf_fpr, rf_tpr, _ = roc_curve(Y_test, rf_probs)\n",
    "# plot the roc curve for the model\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=4)\n",
    "plt.plot(rf_fpr, rf_tpr, marker='.',\n",
    "label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                     ''.format('Ribo', rf_auc))\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load results\n",
    "results = np.load('../results/RF_results_balanced.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy achieved: %.3f'%results['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Average precision achieved: %.3f'%results['average_precision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch = results['test_labels'] != results['pred_labels']\n",
    "mismatch_idx = [i for i,e in enumerate(mismatch) if e ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_df = pd.DataFrame(results['pred_proba'][mismatch_idx], index=results['test_samples'][mismatch_idx], columns=['PolyA', 'Ribo'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of miscalssified samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clinical.loc[misclassified_df.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(results['test_labels'], results['pred_labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix shows good separation between the two calsses\n",
    "* **Class 0**: PolyA libraries\n",
    "* **Class 1**: Ribo-deplete libraries\n",
    "* 4 PolyA samples misclassified as Ribo-deplete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(mat, annot=True)\n",
    "ax.set_ylabel(\"True Label\", fontsize=16)\n",
    "ax.set_xlabel(\"Predicted Label\", fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr = fpr_tpr(mat)\n",
    "print('FPR = {:.3f}, TPR = {:.3f}'.format(fpr, tpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = zip(results['importances'], results['genes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = sorted(importances, key = lambda x:x[0], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = list(map(lambda x:x[0], importances))\n",
    "genes = list(map(lambda x:x[1], importances))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene importance determined by RF classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(np.arange(len(scores[:20])), scores[:20], width=1)\n",
    "plt.xticks(labels=genes[:20], ticks=np.arange(len(scores[:20])), rotation=90)\n",
    "plt.ylabel(\"Importance\", fontsize=15)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../results/RF_gene_rank_balanced.tsv', 'w') as f:\n",
    "    f.write('Gene\\tScore\\n')\n",
    "    for i in range(len(scores)):\n",
    "        score = scores[i]\n",
    "        gene = genes[i]\n",
    "        f.write(gene+'\\t'+str(score)+'\\n')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempting to improve probability threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(results['pred_proba'][:,1])\n",
    "plt.ylabel(\"Number of Samples\", fontsize=15)\n",
    "plt.title('Probability of being Ribo', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df=pd.DataFrame()\n",
    "best_score=None\n",
    "best_cutoff=None\n",
    "best_pred=None\n",
    "for cutoff in np.arange(0,1,0.01):\n",
    "\n",
    "    test_pred_classes=[]\n",
    "    for i in results['pred_proba'][:,1]:\n",
    "        if i>=cutoff:\n",
    "            test_pred_classes+=[1]\n",
    "        else:\n",
    "            test_pred_classes+=[0]\n",
    "            \n",
    "    score=average_precision_score(results['test_labels'],test_pred_classes )\n",
    "    accuracy_df.loc[cutoff, 'Accuracy']=score\n",
    "    #storing predictions with best accuracy score\n",
    "    if best_score is None or score>best_score:\n",
    "        best_score=score\n",
    "        best_cutoff=cutoff\n",
    "        best_pred=test_pred_classes\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "accuracy_df.plot(kind='bar')\n",
    "plt.xlabel('Cutoff')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n",
    "print('Best cutoff: {}'.format(best_cutoff))\n",
    "print('Best accuracy: {}'.format(best_score))\n",
    "\n",
    "# print(accuracy_df.describe())\n",
    "\n",
    "mat_2 = confusion_matrix(results['test_labels'], best_pred)\n",
    "ax2 =sns.heatmap(mat_2, annot=True)\n",
    "ax2.set_ylabel(\"True Label\", fontsize=16)\n",
    "ax2.set_xlabel(\"Predicted Label\", fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr = fpr_tpr(mat_2)\n",
    "print('FPR = {:.3f}, TPR = {:.3f}'.format(fpr, tpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying on rest of PolyA not used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_reduced = pd.read_csv(\"../data_test/Poly.tsv\", sep='\\t', index_col=0)\n",
    "poly = pd.read_csv(\"../data_test/TumorCompendium_v10_PolyA_hugo_log2tpm_58581genes_2019-07-25.tsv\", sep='\\t', index_col=0)\n",
    "poly = poly.loc[poly_reduced.columns.tolist()].T #selecting teh top 5k genes\n",
    "poly_rest = poly.loc[list(set(poly.index).difference(poly_reduced.index))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_rest_pred = model.predict(poly_rest)\n",
    "poly_rest_proba = model.predict_proba(poly_rest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(np.hstack([poly_rest_pred.reshape(-1,1),poly_rest_proba]), columns=[\"Ribo\", \"Proba_Poly\", \"Proba_Ribo\"], index=poly_rest.index).to_csv(\"PolyRestBalancedResults.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(poly_rest_pred==0).sum()/poly_rest.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(poly_rest_pred==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
